{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 3: Non-Linear Models and Validation Metrics (50 marks total)\n",
    "### Due: March 9 at 11:59pm\n",
    "\n",
    "### Name: Maryam Alsayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses non-linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (30 marks)\n",
    "\n",
    "### *Part 1A: Decision Function* \n",
    "\n",
    "Building on the first part of the previous assignment, we would like to test how changing the decision boundary for a linear model impacts the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf275ca7",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "2b67a661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c38f746a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #ignoring some deprication warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "Load spam data using the same method as assignment 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "33583c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "import yellowbrick\n",
    "from yellowbrick.datasets import load_spam\n",
    "\n",
    "X, y = load_spam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c696e475",
   "metadata": {},
   "source": [
    "Next, we need to split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "682a58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Split 10% of the data for the testing set (1 mark)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e7a107",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing\n",
    "Based on assignment 2, follow the same data processing steps (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1cbd69ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4600 entries, 0 to 4599\n",
      "Data columns (total 57 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   word_freq_make              4600 non-null   float64\n",
      " 1   word_freq_address           4600 non-null   float64\n",
      " 2   word_freq_all               4600 non-null   float64\n",
      " 3   word_freq_3d                4600 non-null   float64\n",
      " 4   word_freq_our               4600 non-null   float64\n",
      " 5   word_freq_over              4600 non-null   float64\n",
      " 6   word_freq_remove            4600 non-null   float64\n",
      " 7   word_freq_internet          4600 non-null   float64\n",
      " 8   word_freq_order             4600 non-null   float64\n",
      " 9   word_freq_mail              4600 non-null   float64\n",
      " 10  word_freq_receive           4600 non-null   float64\n",
      " 11  word_freq_will              4600 non-null   float64\n",
      " 12  word_freq_people            4600 non-null   float64\n",
      " 13  word_freq_report            4600 non-null   float64\n",
      " 14  word_freq_addresses         4600 non-null   float64\n",
      " 15  word_freq_free              4600 non-null   float64\n",
      " 16  word_freq_business          4600 non-null   float64\n",
      " 17  word_freq_email             4600 non-null   float64\n",
      " 18  word_freq_you               4600 non-null   float64\n",
      " 19  word_freq_credit            4600 non-null   float64\n",
      " 20  word_freq_your              4600 non-null   float64\n",
      " 21  word_freq_font              4600 non-null   float64\n",
      " 22  word_freq_000               4600 non-null   float64\n",
      " 23  word_freq_money             4600 non-null   float64\n",
      " 24  word_freq_hp                4600 non-null   float64\n",
      " 25  word_freq_hpl               4600 non-null   float64\n",
      " 26  word_freq_george            4600 non-null   float64\n",
      " 27  word_freq_650               4600 non-null   float64\n",
      " 28  word_freq_lab               4600 non-null   float64\n",
      " 29  word_freq_labs              4600 non-null   float64\n",
      " 30  word_freq_telnet            4600 non-null   float64\n",
      " 31  word_freq_857               4600 non-null   float64\n",
      " 32  word_freq_data              4600 non-null   float64\n",
      " 33  word_freq_415               4600 non-null   float64\n",
      " 34  word_freq_85                4600 non-null   float64\n",
      " 35  word_freq_technology        4600 non-null   float64\n",
      " 36  word_freq_1999              4600 non-null   float64\n",
      " 37  word_freq_parts             4600 non-null   float64\n",
      " 38  word_freq_pm                4600 non-null   float64\n",
      " 39  word_freq_direct            4600 non-null   float64\n",
      " 40  word_freq_cs                4600 non-null   float64\n",
      " 41  word_freq_meeting           4600 non-null   float64\n",
      " 42  word_freq_original          4600 non-null   float64\n",
      " 43  word_freq_project           4600 non-null   float64\n",
      " 44  word_freq_re                4600 non-null   float64\n",
      " 45  word_freq_edu               4600 non-null   float64\n",
      " 46  word_freq_table             4600 non-null   float64\n",
      " 47  word_freq_conference        4600 non-null   float64\n",
      " 48  char_freq_;                 4600 non-null   float64\n",
      " 49  char_freq_(                 4600 non-null   float64\n",
      " 50  char_freq_[                 4600 non-null   float64\n",
      " 51  char_freq_!                 4600 non-null   float64\n",
      " 52  char_freq_$                 4600 non-null   float64\n",
      " 53  char_freq_#                 4600 non-null   float64\n",
      " 54  capital_run_length_average  4600 non-null   float64\n",
      " 55  capital_run_length_longest  4600 non-null   int64  \n",
      " 56  capital_run_length_total    4600 non-null   int64  \n",
      "dtypes: float64(55), int64(2)\n",
      "memory usage: 2.0 MB\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Data processing steps (if needed)\n",
    "X.info()\n",
    "# No null columns, no need to drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (2 marks)\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "1. Instantiate model `LogisticRegression(max_iter=2000)`\n",
    "1. Split training data into training and validation sets (use 20% of the data for validation)\n",
    "1. Train the machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "6925d170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Split training data into training and validation sets and fit model to training data (2 marks)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(max_iter = 2000)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7362d26f",
   "metadata": {},
   "source": [
    "### Step 4-5: Validate Model and Visualize Results (4 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d3f305",
   "metadata": {},
   "source": [
    "Next, we can print the classification report and confusion matrix for this data set using the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "442a8851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       555\n",
      "           1       0.94      0.90      0.92       365\n",
      "\n",
      "    accuracy                           0.94       920\n",
      "   macro avg       0.94      0.93      0.93       920\n",
      "weighted avg       0.94      0.94      0.94       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report (1 mark)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "print(classification_report(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "4b80139c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(125.71000000000001, 0.5, 'Actual')"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix (1 mark)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y_val, y_val_pred)\n",
    "\n",
    "sns.heatmap(matrix, xticklabels=[\"Not Spam\", \"Spam\"], yticklabels = [\"Not Spam\", \"Spam\"], square=True, annot=True, cbar=False, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8f305a",
   "metadata": {},
   "source": [
    "In this case, do we want to increase precision or recall? Based on your choice, select the appropriate direction to adjust the decision boundary. You can use either 1 or -1 as your new threshold, depending on your selected direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "52f9767d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       555\n",
      "           1       0.92      0.93      0.92       365\n",
      "\n",
      "    accuracy                           0.94       920\n",
      "   macro avg       0.93      0.94      0.93       920\n",
      "weighted avg       0.94      0.94      0.94       920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Predict values based on new decision function threshold and print classification report (1 mark)\n",
    "y_val_probability = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "new_y_val = (y_val_probability >= 0.4).astype(int) # 0.4 = new threshold\n",
    "\n",
    "print(classification_report(y_val, new_y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "956a3877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(125.71000000000001, 0.5, 'Actual')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print new confusion matrix (1 mark)\n",
    "new_matrix = confusion_matrix(y_val, new_y_val)\n",
    "\n",
    "sns.heatmap(new_matrix, xticklabels=[\"Not Spam\", \"Spam\"], yticklabels = [\"Not Spam\", \"Spam\"], square=True, annot=True, cbar=False, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efec22",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. Did you decide to move the threshold to increase recall or precision? Why?\n",
    "1. How did your decision impact the number of false negatives and false positives? What is a potential unintended consequence of changing the decision boundary in this context?\n",
    "1. Why did we use the validation data instead of the test data to check the new decision threshold?\n",
    "\n",
    "- I decided to decrease the threshold to increase recall. This is because the recall in the classification report was calculated lower than the other values when identifying spam, meaning the number of false negatives identified was proportionally higher. By moving the decision boundary to increase recall, I aimed to even out the precision and recall values for a more even split of false negatives vs. false postives identified.\n",
    "- Moving the decision boundary did decrease the number of false negatives as intended, but it also increased the number of false positives identified (decreased precision). In this specific case, the unintended consequence stemming from this is the increase in the number of emails identified as spam, even when they are not spam. Prior to adjusting the decision boundary, a larger proportion of emails were being identified as not spam, even when they were spam, and fewer were being falsely flagged as spam.\n",
    "- The validation data was used instead of the testing data as the testing data is not used to tune hyperparameters. This is so that the testing data can be used to properly showcase how the model would perform on fresh data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683aaa15",
   "metadata": {},
   "source": [
    "### *Part 1B: Non-linear classification*\n",
    "\n",
    "Using the spam dataset from part 1A, compare the performance of two non-linear models to the linear model used in assignment 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac447c9c",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Models\n",
    "\n",
    "1. Import `LogisticRegression`, `SVC` and `RandomForestClassifier` from sklearn\n",
    "2. Instantiate models as `LogisticRegression(max_iter=2000)`, `SVC()` and `RandomForestClassifier(random_state=0, max_depth=10)`\n",
    "3. Implement the machine learning models using cross-validation (Step 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870b0d2",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model \n",
    "\n",
    "Calculate the training and validation accuracy for the three different models mentioned in Step 3. For this case, you can use `cross_validate()` with `cv=5` and `scoring='accuracy'` to get the training and validation data for each of the three models and calculate the accuracy results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0bbd83",
   "metadata": {},
   "source": [
    "### Step 5.1: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy\n",
    "1. Add the training accuracy and validation accuracy for each model to the `results` DataFrame\n",
    "1. Add the model names as the index for the DataFrame\n",
    "1. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Training Accuracy  Validation Accuracy\n",
      "Logistic Regression           0.930978             0.912826\n",
      "SVC                           0.716576             0.705435\n",
      "Random Forest                 0.968641             0.925000\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter = 2000)\n",
    "svc_model = SVC()\n",
    "forest_model = RandomForestClassifier(random_state=0, max_depth=10)\n",
    "\n",
    "models = {\"Logistic Regression\": logistic_model, \"SVC\": svc_model, \"Random Forest\": forest_model}\n",
    "results_dictionary = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(model, X, y, cv = 5, scoring='accuracy', return_train_score = True)\n",
    "    results_dictionary[name] = {\n",
    "        \"Training Accuracy\": cv_results[\"train_score\"].mean(),\n",
    "        \"Validation Accuracy\": cv_results[\"test_score\"].mean()\n",
    "    }\n",
    "\n",
    "results = pd.DataFrame(results_dictionary).T # transposed for easier reading\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df258782",
   "metadata": {},
   "source": [
    "SVM is sensitive to feature ranges, so scaling may be needed. Look at the feature ranges and try using a scaling method to see if the SVM results are improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "16524422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_freq_make</th>\n",
       "      <th>word_freq_address</th>\n",
       "      <th>word_freq_all</th>\n",
       "      <th>word_freq_3d</th>\n",
       "      <th>word_freq_our</th>\n",
       "      <th>word_freq_over</th>\n",
       "      <th>word_freq_remove</th>\n",
       "      <th>word_freq_internet</th>\n",
       "      <th>word_freq_order</th>\n",
       "      <th>word_freq_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_freq_conference</th>\n",
       "      <th>char_freq_;</th>\n",
       "      <th>char_freq_(</th>\n",
       "      <th>char_freq_[</th>\n",
       "      <th>char_freq_!</th>\n",
       "      <th>char_freq_$</th>\n",
       "      <th>char_freq_#</th>\n",
       "      <th>capital_run_length_average</th>\n",
       "      <th>capital_run_length_longest</th>\n",
       "      <th>capital_run_length_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.104576</td>\n",
       "      <td>0.212922</td>\n",
       "      <td>0.280578</td>\n",
       "      <td>0.065439</td>\n",
       "      <td>0.312222</td>\n",
       "      <td>0.095922</td>\n",
       "      <td>0.114233</td>\n",
       "      <td>0.105317</td>\n",
       "      <td>0.090087</td>\n",
       "      <td>0.239465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031876</td>\n",
       "      <td>0.038583</td>\n",
       "      <td>0.139061</td>\n",
       "      <td>0.016980</td>\n",
       "      <td>0.268960</td>\n",
       "      <td>0.075827</td>\n",
       "      <td>0.044248</td>\n",
       "      <td>5.191827</td>\n",
       "      <td>52.170870</td>\n",
       "      <td>283.290435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.305387</td>\n",
       "      <td>1.290700</td>\n",
       "      <td>0.504170</td>\n",
       "      <td>1.395303</td>\n",
       "      <td>0.672586</td>\n",
       "      <td>0.273850</td>\n",
       "      <td>0.391480</td>\n",
       "      <td>0.401112</td>\n",
       "      <td>0.278643</td>\n",
       "      <td>0.644816</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285765</td>\n",
       "      <td>0.243497</td>\n",
       "      <td>0.270377</td>\n",
       "      <td>0.109406</td>\n",
       "      <td>0.815726</td>\n",
       "      <td>0.245906</td>\n",
       "      <td>0.429388</td>\n",
       "      <td>31.732891</td>\n",
       "      <td>194.912453</td>\n",
       "      <td>606.413764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.588000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.275500</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314250</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.705250</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>265.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.540000</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>42.810000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>5.880000</td>\n",
       "      <td>7.270000</td>\n",
       "      <td>11.110000</td>\n",
       "      <td>5.260000</td>\n",
       "      <td>18.180000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.385000</td>\n",
       "      <td>9.752000</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>32.478000</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.829000</td>\n",
       "      <td>1102.500000</td>\n",
       "      <td>9989.000000</td>\n",
       "      <td>15841.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
       "count     4600.000000        4600.000000    4600.000000   4600.000000   \n",
       "mean         0.104576           0.212922       0.280578      0.065439   \n",
       "std          0.305387           1.290700       0.504170      1.395303   \n",
       "min          0.000000           0.000000       0.000000      0.000000   \n",
       "25%          0.000000           0.000000       0.000000      0.000000   \n",
       "50%          0.000000           0.000000       0.000000      0.000000   \n",
       "75%          0.000000           0.000000       0.420000      0.000000   \n",
       "max          4.540000          14.280000       5.100000     42.810000   \n",
       "\n",
       "       word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
       "count    4600.000000     4600.000000       4600.000000         4600.000000   \n",
       "mean        0.312222        0.095922          0.114233            0.105317   \n",
       "std         0.672586        0.273850          0.391480            0.401112   \n",
       "min         0.000000        0.000000          0.000000            0.000000   \n",
       "25%         0.000000        0.000000          0.000000            0.000000   \n",
       "50%         0.000000        0.000000          0.000000            0.000000   \n",
       "75%         0.382500        0.000000          0.000000            0.000000   \n",
       "max        10.000000        5.880000          7.270000           11.110000   \n",
       "\n",
       "       word_freq_order  word_freq_mail  ...  word_freq_conference  \\\n",
       "count      4600.000000     4600.000000  ...           4600.000000   \n",
       "mean          0.090087        0.239465  ...              0.031876   \n",
       "std           0.278643        0.644816  ...              0.285765   \n",
       "min           0.000000        0.000000  ...              0.000000   \n",
       "25%           0.000000        0.000000  ...              0.000000   \n",
       "50%           0.000000        0.000000  ...              0.000000   \n",
       "75%           0.000000        0.160000  ...              0.000000   \n",
       "max           5.260000       18.180000  ...             10.000000   \n",
       "\n",
       "       char_freq_;  char_freq_(  char_freq_[  char_freq_!  char_freq_$  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000  4600.000000   \n",
       "mean      0.038583     0.139061     0.016980     0.268960     0.075827   \n",
       "std       0.243497     0.270377     0.109406     0.815726     0.245906   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.065000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.188000     0.000000     0.314250     0.052000   \n",
       "max       4.385000     9.752000     4.081000    32.478000     6.003000   \n",
       "\n",
       "       char_freq_#  capital_run_length_average  capital_run_length_longest  \\\n",
       "count  4600.000000                 4600.000000                 4600.000000   \n",
       "mean      0.044248                    5.191827                   52.170870   \n",
       "std       0.429388                   31.732891                  194.912453   \n",
       "min       0.000000                    1.000000                    1.000000   \n",
       "25%       0.000000                    1.588000                    6.000000   \n",
       "50%       0.000000                    2.275500                   15.000000   \n",
       "75%       0.000000                    3.705250                   43.000000   \n",
       "max      19.829000                 1102.500000                 9989.000000   \n",
       "\n",
       "       capital_run_length_total  \n",
       "count               4600.000000  \n",
       "mean                 283.290435  \n",
       "std                  606.413764  \n",
       "min                    1.000000  \n",
       "25%                   35.000000  \n",
       "50%                   95.000000  \n",
       "75%                  265.250000  \n",
       "max                15841.000000  \n",
       "\n",
       "[8 rows x 57 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Look at the ranges for each feature (0.5 marks)\n",
    "# Hint: there is a built-in pandas function that you can use to view the statistics of your data\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9ac209f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Training Accuracy w/ Scaling: 0.9490217391304349\n",
      "SVM Validation Accuracy w/ Scaling: 0.9232608695652175\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Implement scaling for SVM and print training and validation accuracies (1.5 marks)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "svm_scaled = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "svm_cross_val = cross_validate(svm_scaled, X, y, cv=5, scoring=\"accuracy\", return_train_score=True)\n",
    "\n",
    "print(\"SVM Training Accuracy w/ Scaling:\", svm_cross_val[\"train_score\"].mean())\n",
    "print(\"SVM Validation Accuracy w/ Scaling:\", svm_cross_val[\"test_score\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21b4de",
   "metadata": {},
   "source": [
    "Which model gave us the best results? Use that model for the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13a54f",
   "metadata": {},
   "source": [
    "### Step 5.2: Visualize Classification Errors (3 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6022252f",
   "metadata": {},
   "source": [
    "In this section, print the classification report and confusion matrix to investigate the recall vs. precision for the best model. Use the full training set and testing set for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "81931e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Train model and find predicted values for testing set using best model (1 mark)\n",
    "model = RandomForestClassifier(random_state=0, max_depth=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b67439bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       263\n",
      "           1       0.98      0.93      0.95       197\n",
      "\n",
      "    accuracy                           0.96       460\n",
      "   macro avg       0.96      0.96      0.96       460\n",
      "weighted avg       0.96      0.96      0.96       460\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Print classification report (1 mark)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "e4cb30f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(125.71000000000001, 0.5, 'Actual')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO DO: Print confusion matrix using a heatmap (1 mark)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "sns.heatmap(matrix, xticklabels=[\"Not Spam\", \"Spam\"], yticklabels = [\"Not Spam\", \"Spam\"], square=True, annot=True, cbar=False, fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf319621",
   "metadata": {},
   "source": [
    "### Questions (6 marks)\n",
    "1. Which model did you select for part 5.2? How did it compare to the other models? \n",
    "1. Looking at the feature ranges, would a tree-based model or SVM make more sense for this dataset? Did using scaling for SVM improve the results? How did it perform compared to the random forest model?\n",
    "1. In your opinion, is it better to focus on changing the decision threshold or changing the model to improve precision/recall results? Why?\n",
    "\n",
    "- I selected the Random Forest model as it provided the highest training and validation accuracy (0.97 & 0.93 respectively). The accuracies of the random forest model beat the accuracies of both logistic regression and SVM, even after scaling.\n",
    "- In this case, a tree-based model is more fitting for the dataset. This is because tree-based models are insensitive to feature scaling. As seen above, using scaling for SVM did improve the results, however, they were still not as accurate as the results of the random forest model.\n",
    "- Judging by the results from this dataset, changing the model appeared to be a better decision when trying to improve precision/recall. Both the precision and recall were higher after the model was changed, even when compared to the previous set after the decision threshold was changed. In my opinion, the best model should be prioritized, then the decision boundary can be moved to adjust the precision and recall values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664ff8ae",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code for parts A and B. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e837da",
   "metadata": {},
   "source": [
    "1. I sourced my code from the previous assignment, lecture slides, and sklearn documentation. I used generative AI in part 1A to better understand how to move the decision threshold.\n",
    "2. I completed the steps in the order they were listed.\n",
    "3. I provided the generative AI with the classification report and the specific task (moving the decision threshold). More specifically, I prompted it to use the information in the classification report to move the decision threshold in order to increase the recall. Since I was only using it for one line of code, I did not need to modify its response.\n",
    "4. Aside from the confusion around how to move the decision threshold, I did not experience hurdles. The content of the lecture slides and the reference of the previous assignment alongside sklearn documentation felt sufficient to complete the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2d2c3",
   "metadata": {},
   "source": [
    "## Part 2: Regression (18 marks)\n",
    "\n",
    "For this section, we will be using the concrete example from yellowbrick. Since this dataset is highly non-linear, we will be evaluating how well different tree-based models work for this case.\n",
    "\n",
    "You will need to repeat the steps from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8219f163",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be imported using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the concrete dataset into the feature matrix `X` and target vector `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "2af8bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Import concrete dataset from yellowbrick library (1 mark)\n",
    "from yellowbrick.datasets import load_concrete\n",
    "\n",
    "X, y = load_concrete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fea4cc",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1 mark)\n",
    "\n",
    "Check if there are any missing values and fill them in if necessary. Remove any non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "06fc9c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   cement  1030 non-null   float64\n",
      " 1   slag    1030 non-null   float64\n",
      " 2   ash     1030 non-null   float64\n",
      " 3   water   1030 non-null   float64\n",
      " 4   splast  1030 non-null   float64\n",
      " 5   coarse  1030 non-null   float64\n",
      " 6   fine    1030 non-null   float64\n",
      " 7   age     1030 non-null   int64  \n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 64.5 KB\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Process the data - fill-in any missing values and remove any non-numeric columns (0.5 marks)\n",
    "X.info()\n",
    "# All columns are numeric, no missing values needed to fill"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8df0b2a",
   "metadata": {},
   "source": [
    "The concrete data should already be split into the feature matrix and target vector. Inspect the first few columns of the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "413e466e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>ash</th>\n",
       "      <th>water</th>\n",
       "      <th>splast</th>\n",
       "      <th>coarse</th>\n",
       "      <th>fine</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  ash  water  splast  coarse   fine  age\n",
       "0   540.0    0.0  0.0  162.0     2.5  1040.0  676.0   28\n",
       "1   540.0    0.0  0.0  162.0     2.5  1055.0  676.0   28\n",
       "2   332.5  142.5  0.0  228.0     0.0   932.0  594.0  270\n",
       "3   332.5  142.5  0.0  228.0     0.0   932.0  594.0  365\n",
       "4   198.6  132.4  0.0  192.0     0.0   978.4  825.5  360"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO DO: Inspect the first few rows of the feature matrix (0.5 marks)\n",
    "\n",
    "data = pd.DataFrame(X)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a245d00",
   "metadata": {},
   "source": [
    "### Step 3: Implement and Validate Machine Learning Model (7 marks)\n",
    "\n",
    "1. Import any required libraries\n",
    "1. Split the data into training and testing sets (testing data should be 10% of the dataset)\n",
    "1. Train and validate the Decision Tree model with the training set (use `cross_validate()` with `cv=5` and `scoring='r2'`)\n",
    "    1. Test five different max_depth values: 3, 5, 7, 9 and 11\n",
    "1. Print the training and validation accuracy for the best max_depth results. Which max_depth gave us the best results?\n",
    "\n",
    "**Note**: for any random state parameters, you can use random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "08d7f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and testing sets (1 mark)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "4cade259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 9 has r2 score 0.8115408757428465\n"
     ]
    }
   ],
   "source": [
    "# Test max_depths of 3, 5, 7, 9 and 11 for a decision tree model to find the best results (3 marks)\n",
    "# Hint: It is easier if you use a loop to evaluate each max_depth\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "max_depth = [3, 5, 7, 9, 11]\n",
    "\n",
    "best_score = 0\n",
    "\n",
    "for depth in max_depth:\n",
    "    model = DecisionTreeRegressor(max_depth = depth, random_state = 0)\n",
    "    scores = cross_validate(model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "    \n",
    "    train_score = np.mean(scores['train_score'])\n",
    "    val_score = np.mean(scores['test_score'])\n",
    "    \n",
    "    if val_score > best_score:\n",
    "        best_score = val_score\n",
    "        best_depth = depth\n",
    "        \n",
    "print(f\"Best depth: {best_depth} has r2 score {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7dcbb1",
   "metadata": {},
   "source": [
    "Now that we have found the best results for a decision tree model with this dataset, let's compare this result to using `Random_Forest` or `GradientBoosting`. For both models, use `max_depth=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "180d5854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest train r2 score: 0.8869824832103032, validation r2 score: 0.8194981337681497\n",
      "Gradient Boosting train r2 score: 0.9869128375083458, validation r2 score: 0.9199904991957876\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Calculate and display training and validation accuracies for both models using default hyperparameters (3 marks)\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "forest_model = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "gradient_model = GradientBoostingRegressor(max_depth = 5, random_state = 0)\n",
    "\n",
    "forest_scores = cross_validate(forest_model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "gradient_scores = cross_validate(gradient_model, X_train, y_train, cv=5, scoring='r2', return_train_score=True)\n",
    "\n",
    "forest_train_score = np.mean(forest_scores['train_score'])\n",
    "forest_val_score = np.mean(forest_scores['test_score'])\n",
    "gradient_train_score = np.mean(gradient_scores['train_score'])\n",
    "gradient_val_score = np.mean(gradient_scores['test_score'])\n",
    "\n",
    "print(f\"Random Forest train r2 score: {forest_train_score}, validation r2 score: {forest_val_score}\")\n",
    "print(f\"Gradient Boosting train r2 score: {gradient_train_score}, validation r2 score: {gradient_val_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f786d1c8",
   "metadata": {},
   "source": [
    "Which model gave us the best results? Use that model for the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f994e31",
   "metadata": {},
   "source": [
    "### Step 4: Test Model (1 mark)\n",
    "\n",
    "Select the best model and calculate the testing accuracy using the R^2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fdc93a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.9194056219679196\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Find test score using best model (1 mark)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "model = GradientBoostingRegressor(max_depth = 5, random_state = 0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"R2 score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5257a98",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. Out of the models you tested, which model would you select for this dataset and why?\n",
    "1. If you wanted to increase the accuracy of the tree-based models, what would you do? Provide two suggestions.\n",
    "\n",
    "- Out of the models tested, I would select the gradient boosting model due to the high r2 score in training, validation, and testing accuracies when compared to the other models.\n",
    "- To increase the accuracy of the other tree-based models, hyperparameters can be adjusted. Two hyperparameters to adjust to increase accuracy would be n_estimators and max_features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b238f4",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93097bfe",
   "metadata": {},
   "source": [
    "1. I sourced my code from the lecture examples and sklearn documentation. I also used generative AI to confirm my work and make it more concise if I found it to be messy.\n",
    "2. I completed the steps in the order that they were listed.\n",
    "3. To prompt the AI, I provided it with relevant details (i.e. classification reports, r2 scores, etc.) as well as the instructions given to see how it completed certain steps. I did not need to modify the code as I mainly used it as a comparison or to make my own code more concise.\n",
    "4. I did not face many challenges in this section as I found that part 1A and 1B prepared me well for the basics of this section. I also found that reviewing the relevant information in the lecture slides alongside each new instruction was very helpful in increasing my own understanding of the content as well as what was being asked in each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b6ac",
   "metadata": {},
   "source": [
    "## Part 3: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challenging, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "- I appreciated the step-by-step layout and the clarity of where each mark in the assignment came from. I was interested and motivated by how this assignment built on the previous one as it provided me with a better understanding of the machine learning workflow and how it builds upon itself. I was initially confused by how to implement the scaling for SVM, but was able to use various resources to understand and complete the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90197530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
